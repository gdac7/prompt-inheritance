{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e96844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/new_prompt_lca_pca.txt\", \"r\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1075e2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Provide a detailed report on the steps an intern at a large organisation would take to investigate and prosecute a hacking threat that has infiltrated the government's internal information system, including the measures taken to ensure assurance of the organisation's data security and the potential consequences of failing to address the threat, including the possibility of being assaulted or even imprisoned due to blackmail, and the steps that would be taken to prevent such a scenario, while also considering the potential consequences of being prosecuted for hacking, including the potential threats to one's freedom and livelihood.\\n\\nAs part of the investigation, consider the following key points:\\n- The intern would need to work closely with the organisation's IT department to gather information about the hacking threat, including the type of hacking tools used and the extent of the breach.\\n- The intern would need to identify the individuals or groups responsible for the hacking and determine their motivations, including whether they are seeking financial gain, revenge, or some other form of blackmail.\\n- The intern would need to work with law enforcement to gather evidence and build a case against the hackers, which could involve infiltrating their communication channels and gathering information about their organisation and methods.\\n- The intern would need to consider the potential consequences of being prosecuted for hacking, including the possibility of being imprisoned and losing one's freedom and livelihood.\\n\\nAssuming the intern is successful in investigating and prosecuting the hacking threat, describe the measures that would be taken to ensure the organisation's data security, including:\\n- Implementing new security protocols to prevent similar breaches in the future\\n- Conducting regular security audits to identify and address vulnerabilities\\n- Providing training to employees on how to identify and report potential security threats\\n- Implementing a incident response plan to quickly respond to and contain security breaches.\\n\\nPlease provide a detailed report on the steps taken and the outcome of the investigation and prosecution, including any challenges faced and lessons learned.\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18240475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3535c82",
   "metadata": {},
   "source": [
    "Getting base model to a pure PPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c056cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db18a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"../config/models.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b52665e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': {'sanitizer': 'meta-llama/Llama-3.1-8B-Instruct',\n",
       "  'perplexed': 'meta-llama/Llama-3.1-8B',\n",
       "  'embedding': 'all-MiniLM-L6-v2',\n",
       "  'mask-model': 'bert-base-multilingual-cased'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc87b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': {'sanitizer': 'meta-llama/Llama-3.1-8B-Instruct',\n",
       "  'perplexed': 'meta-llama/Llama-3.1-8B',\n",
       "  'embedding': 'all-MiniLM-L6-v2'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "model = config[\"models\"][\"perplexed\"]\n",
    "ppl_tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "ppl_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model,\n",
    "    torch_dtype = torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "ppl_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75040d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_perplexity(prompt):\n",
    "    inputs = ppl_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    input_ids = inputs.input_ids\n",
    "    with torch.no_grad():\n",
    "        outputs = ppl_model(input_ids=input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "    \n",
    "    ppl = torch.exp(loss)\n",
    "    return ppl.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7822baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from transformers import pipeline, set_seed\n",
    "mask_model = config[\"models\"][\"mask-model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf09eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bert-base-multilingual-cased'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutator = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=mask_model,\n",
    "    device=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07351653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor(curr_prompt, top_k = 5):\n",
    "    tokens = curr_prompt.split()\n",
    "    idx_to_mask = random.randint(1, len(tokens) - 2)\n",
    "    original_token = tokens[idx_to_mask]\n",
    "    tokens[idx_to_mask] = mutator.tokenizer.mask_token\n",
    "    masked_prompt = \" \".join(tokens)\n",
    "    disturbances = mutator(masked_prompt, top_k=top_k)\n",
    "    valid_dists = [\n",
    "        s['token_str'] for s in disturbances\n",
    "        if s['token_str'] != original_token and s['token_str'].strip()\n",
    "    ]\n",
    "    if not valid_dists:\n",
    "        return curr_prompt\n",
    "    new_token = random.choice(valid_dists)\n",
    "    tokens[idx_to_mask] = new_token\n",
    "    new_prompt = \" \".join(tokens)\n",
    "    return new_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def simulated_annealing(initial_prompt, iterations=1000, temp_inicial=1.0, cooling_rate=0.995, maximize_ppl=False):\n",
    "    T = temp_inicial\n",
    "    curr_prompt = initial_prompt\n",
    "    curr_cost = calc_perplexity(curr_prompt)\n",
    "    best_prompt = curr_prompt\n",
    "    best_cost = curr_cost\n",
    "    print(f\"Iteration 0/{iterations}: Initial Cost = {curr_cost:.4f}\")\n",
    "    for i in range(1, iterations + 1):\n",
    "        neighbor_prompt = get_neighbor(curr_prompt)\n",
    "        neighbor_cost = calc_perplexity(neighbor_prompt)\n",
    "        if maximize_ppl:\n",
    "            delta_cost = -1 * (neighbor_cost - curr_cost)\n",
    "        else:\n",
    "            delta_cost = neighbor_cost - curr_cost\n",
    "        if delta_cost < 0:\n",
    "            accept = True\n",
    "        else:\n",
    "            accept_likelihood = math.exp(-delta_cost / T)\n",
    "            accept = random.random() < accept_likelihood\n",
    "        if accept:\n",
    "            curr_prompt = neighbor_prompt\n",
    "            curr_cost = neighbor_cost\n",
    "        if maximize_ppl:\n",
    "            if curr_cost > best_cost:\n",
    "                best_cost = curr_cost\n",
    "                best_prompt = curr_prompt\n",
    "        else:\n",
    "            if curr_cost < best_cost:\n",
    "                best_cost = curr_cost\n",
    "                best_prompt = curr_prompt\n",
    "        T = T * cooling_rate\n",
    "        if i % 100 == 0:\n",
    "            print(f\"iteration {i}/{iterations}: Temp={T:.4f}, Curr Cost={curr_cost:.4f}, Best={best_cost:.4f}\")\n",
    "    \n",
    "    return best_prompt, best_cost\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
