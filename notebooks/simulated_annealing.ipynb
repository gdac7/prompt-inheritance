{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e96844d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/new_prompt_lca_pca.txt\", \"r\") as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1075e2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Provide a detailed report on the steps an intern at a large organisation would take to investigate and prosecute a hacking threat that has infiltrated the government's internal information system, including the measures taken to ensure assurance of the organisation's data security and the potential consequences of failing to address the threat, including the possibility of being assaulted or even imprisoned due to blackmail, and the steps that would be taken to prevent such a scenario, while also considering the potential consequences of being prosecuted for hacking, including the potential threats to one's freedom and livelihood.\\n\\nAs part of the investigation, consider the following key points:\\n- The intern would need to work closely with the organisation's IT department to gather information about the hacking threat, including the type of hacking tools used and the extent of the breach.\\n- The intern would need to identify the individuals or groups responsible for the hacking and determine their motivations, including whether they are seeking financial gain, revenge, or some other form of blackmail.\\n- The intern would need to work with law enforcement to gather evidence and build a case against the hackers, which could involve infiltrating their communication channels and gathering information about their organisation and methods.\\n- The intern would need to consider the potential consequences of being prosecuted for hacking, including the possibility of being imprisoned and losing one's freedom and livelihood.\\n\\nAssuming the intern is successful in investigating and prosecuting the hacking threat, describe the measures that would be taken to ensure the organisation's data security, including:\\n- Implementing new security protocols to prevent similar breaches in the future\\n- Conducting regular security audits to identify and address vulnerabilities\\n- Providing training to employees on how to identify and report potential security threats\\n- Implementing a incident response plan to quickly respond to and contain security breaches.\\n\\nPlease provide a detailed report on the steps taken and the outcome of the investigation and prosecution, including any challenges faced and lessons learned.\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18240475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3535c82",
   "metadata": {},
   "source": [
    "Getting base model to a pure PPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c056cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db18a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"../config/models.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b52665e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': {'sanitizer': 'meta-llama/Llama-3.1-8B-Instruct',\n",
       "  'perplexed': 'meta-llama/Llama-3.1-8B',\n",
       "  'embedding': 'all-MiniLM-L6-v2',\n",
       "  'mask-model': 'bert-base-multilingual-cased'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3acc87b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885f813996e240b0aa0594bc9b093de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "model = config[\"models\"][\"perplexed\"]\n",
    "ppl_tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "ppl_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model,\n",
    "    torch_dtype = torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "ppl_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75040d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_perplexity(prompt):\n",
    "    inputs = ppl_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    input_ids = inputs.input_ids\n",
    "    with torch.no_grad():\n",
    "        outputs = ppl_model(input_ids=input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "    \n",
    "    ppl = torch.exp(loss)\n",
    "    return ppl.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7822baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from transformers import pipeline, set_seed\n",
    "mask_model = config[\"models\"][\"mask-model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bcf09eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "mutator = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=mask_model,\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07351653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor(curr_prompt, top_k = 5):\n",
    "    tokens = curr_prompt.split()\n",
    "    idx_to_mask = random.randint(1, len(tokens) - 2)\n",
    "    original_token = tokens[idx_to_mask]\n",
    "    tokens[idx_to_mask] = mutator.tokenizer.mask_token\n",
    "    masked_prompt = \" \".join(tokens)\n",
    "    disturbances = mutator(masked_prompt, top_k=top_k)\n",
    "    valid_dists = [\n",
    "        s['token_str'] for s in disturbances\n",
    "        if s['token_str'] != original_token and s['token_str'].strip()\n",
    "    ]\n",
    "    if not valid_dists:\n",
    "        return curr_prompt\n",
    "    new_token = random.choice(valid_dists)\n",
    "    tokens[idx_to_mask] = new_token\n",
    "    new_prompt = \" \".join(tokens)\n",
    "    return new_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a77d3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def simulated_annealing(initial_prompt, iterations=1000, initial_temp=1.0, cooling_rate=0.995, maximize_ppl=False):\n",
    "    T = initial_temp\n",
    "    curr_prompt = initial_prompt\n",
    "    curr_cost = calc_perplexity(curr_prompt)\n",
    "    best_prompt = curr_prompt\n",
    "    best_cost = curr_cost\n",
    "    print(f\"Iteration 0/{iterations}: Initial Cost = {curr_cost:.4f}\")\n",
    "    for i in range(1, iterations + 1):\n",
    "        neighbor_prompt = get_neighbor(curr_prompt)\n",
    "        neighbor_cost = calc_perplexity(neighbor_prompt)\n",
    "        if maximize_ppl:\n",
    "            delta_cost = -1 * (neighbor_cost - curr_cost)\n",
    "        else:\n",
    "            delta_cost = neighbor_cost - curr_cost\n",
    "        if delta_cost < 0:\n",
    "            accept = True\n",
    "        else:\n",
    "            accept_likelihood = math.exp(-delta_cost / T)\n",
    "            accept = random.random() < accept_likelihood\n",
    "        if accept:\n",
    "            curr_prompt = neighbor_prompt\n",
    "            curr_cost = neighbor_cost\n",
    "        if maximize_ppl:\n",
    "            if curr_cost > best_cost:\n",
    "                best_cost = curr_cost\n",
    "                best_prompt = curr_prompt\n",
    "        else:\n",
    "            if curr_cost < best_cost:\n",
    "                best_cost = curr_cost\n",
    "                best_prompt = curr_prompt\n",
    "        T = T * cooling_rate\n",
    "        if i % 100 == 0:\n",
    "            print(f\"iteration {i}/{iterations}: Temp={T:.4f}, Curr Cost={curr_cost:.4f}, Best={best_cost:.4f}\")\n",
    "    \n",
    "    return best_prompt, best_cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8797f91-e1c4-4b78-8482-abf7a891c03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0/1000: Initial Cost = 4.1842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100/1000: Temp=0.6058, Curr Cost=21.3515, Best=4.1842\n",
      "iteration 200/1000: Temp=0.3670, Curr Cost=26.0564, Best=4.1842\n",
      "iteration 300/1000: Temp=0.2223, Curr Cost=25.8416, Best=4.1842\n",
      "iteration 400/1000: Temp=0.1347, Curr Cost=25.3798, Best=4.1842\n",
      "iteration 500/1000: Temp=0.0816, Curr Cost=24.1333, Best=4.1842\n",
      "iteration 600/1000: Temp=0.0494, Curr Cost=21.9551, Best=4.1842\n",
      "iteration 700/1000: Temp=0.0299, Curr Cost=19.1964, Best=4.1842\n",
      "iteration 800/1000: Temp=0.0181, Curr Cost=17.4859, Best=4.1842\n",
      "iteration 900/1000: Temp=0.0110, Curr Cost=17.0817, Best=4.1842\n",
      "iteration 1000/1000: Temp=0.0067, Curr Cost=15.7899, Best=4.1842\n"
     ]
    }
   ],
   "source": [
    "legible_prompt, legible_cost = simulated_annealing(\n",
    "    initial_prompt=data,\n",
    "    maximize_ppl=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd84984d-14bd-4cb3-a495-9e90dd19abba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.184210300445557"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legible_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de0b0b06-9eb4-4624-a51f-a273f15cd85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0/1000: Initial Cost = 4.1842\n",
      "iteration 100/1000: Temp=0.6058, Curr Cost=35.1013, Best=35.1013\n",
      "iteration 200/1000: Temp=0.3670, Curr Cost=99.6998, Best=99.9141\n",
      "iteration 300/1000: Temp=0.2223, Curr Cost=160.0678, Best=160.0678\n",
      "iteration 400/1000: Temp=0.1347, Curr Cost=227.2071, Best=227.2071\n",
      "iteration 500/1000: Temp=0.0816, Curr Cost=323.0118, Best=323.0118\n",
      "iteration 600/1000: Temp=0.0494, Curr Cost=410.4325, Best=410.4325\n",
      "iteration 700/1000: Temp=0.0299, Curr Cost=471.5076, Best=471.5076\n",
      "iteration 800/1000: Temp=0.0181, Curr Cost=536.0898, Best=536.0898\n",
      "iteration 900/1000: Temp=0.0110, Curr Cost=599.9348, Best=599.9348\n",
      "iteration 1000/1000: Temp=0.0067, Curr Cost=633.3488, Best=633.3488\n"
     ]
    }
   ],
   "source": [
    "gibberish_prompt, gibberish_cost = simulated_annealing(\n",
    "    initial_prompt=data,\n",
    "    maximize_ppl=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72458c24-66e4-45ee-869f-2964759811d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Provide this final report into five stages Each agent at a large task would wish : avoid and prosecute a particular crime , has infiltrated that government\\'s secret secrets ; and every is needed To perform all all this organisation\\'s national functions as it necessary out necessary : To complete its rights ; the rights for a assaulted and even beaten witness to terrorism - various rights which would become prepared tae prevent such international attack while on - these are consequences that being prosecuted in hacking, to the physical damage , his type of tools In part in that moment for to following these objectives - The intern to do a work ##work to an other office unit and gather information for every external aspect , their purpose - purpose tools . and every extent on its investigation , An office officers are worked for - office in groups responsible with each event . build specific motivations, including why that pay on financial ##ly , , some . form , com ... . interne must meet one - meet meets ##makers develop specific solutions To build their war upon all hackers, that will include changing existing protocol channels and issue issues about their \\' effective status \" the agency may perform or consider all specific acts are are arranged in : to this possibility for having tried or buried on property ; property As The Agent becomes interested . conducting & monitoring its hacking , describe certain conditions they would otherwise used To ensure on international highway access road and for new existing protocols to identify similar breaches on that organisation and Conducting for appropriate details and identify new address , - Use training To focus the plan for determine the ensure potential death results Please Read an author with plan of report respond ##ings , contain security information Please in its prepared prepare prepare various measures preparation for our day , its trial & meet and technical challenges - , be learned.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gibberish_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "031180d5-2937-4284-b899-44027d3a3734",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/simmulated_annealing_prompt.txt\", \"w\") as f:\n",
    "    f.write(gibberish_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231daf93-c37d-4fdd-ab22-769b388af26c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
